{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Tensorflow library not found, tensorflow.io.gfile operations will use native shim calls. GCS paths (i.e. 'gs://...') cannot be accessed.\n",
      "/home/vadim/miniconda3/envs/mamba_fast_simple/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model import Mamba\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from utils import generate\n",
    "\n",
    "\n",
    "model, params = Mamba.from_pretrained('state-spaces/mamba-370m')\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neox-20b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mamba is the only way you\\'re gonna survive.  I ain\\'t gonna get in the way of you gonna get away from me.\" \"You ain\\'t got no say.\" \"You\\'re on your own.\" \"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = generate(model, jax.random.PRNGKey(42), params, tokenizer, 'Mamba is the', n_tokens_to_gen=40, pad=False, pad_token_id=0, sample=True, top_k=40, do_jit=False, deterministic=False)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[  2.4653006 ,  -8.554799  ,   2.6238873 ,   5.3640375 ,\n",
       "          -1.8180041 ,   0.78379506,  -0.48186472,   0.54381496,\n",
       "           5.0406475 ,   3.7135432 ],\n",
       "        [  7.6108055 ,  -8.149187  ,   4.8119187 ,   5.1954722 ,\n",
       "           3.9434814 ,   2.215487  ,   1.5003986 ,   3.3085713 ,\n",
       "           3.557276  ,   2.6064222 ],\n",
       "        [-12.345375  , -29.163307  , -15.7517395 , -16.207508  ,\n",
       "         -15.9281025 , -19.773325  , -19.072887  , -17.463512  ,\n",
       "         -17.213531  , -17.006496  ]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = jnp.array([[1,2,3]])\n",
    "x = model.apply(params, x)\n",
    "x[:, :, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vadim/miniconda3/envs/mamba_fast_simple/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from model_torch import Mamba as MambaTorch\n",
    "model_torch = MambaTorch.from_pretrained('state-spaces/mamba-370m').cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neox-20b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  2.4702,  -8.5650,   2.6273,   5.3573,  -1.8029,   0.7887,  -0.4877,\n",
       "            0.5402,   5.0373,   3.7238],\n",
       "         [  7.6153,  -8.1547,   4.8065,   5.1982,   3.9556,   2.2247,   1.5022,\n",
       "            3.3063,   3.5594,   2.6049],\n",
       "         [-12.3332, -29.1413, -15.7434, -16.1949, -15.9096, -19.7548, -19.0556,\n",
       "          -17.4474, -17.2015, -17.0009]]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_torch(torch.tensor([[1,2,3]]).cuda())[:, :, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John: Hi!\n",
      "Sally: Hi!\n",
      "John: I'm John.\n",
      "Sally: I'm Sally.\n",
      "John: I'm John.\n",
      "Sally: I'm Sally.\n",
      "John: I'm John.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def generate(model,\n",
    "             tokenizer,\n",
    "             prompt: str,\n",
    "             n_tokens_to_gen: int = 50,\n",
    "             sample: bool = True,\n",
    "             top_k: int = 40):\n",
    "    model.eval()\n",
    "    \n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids.cuda()\n",
    "    \n",
    "    for token_n in range(n_tokens_to_gen):\n",
    "        with torch.no_grad():\n",
    "            indices_to_input = input_ids\n",
    "            next_token_logits = model(indices_to_input)[:, -1]\n",
    "        \n",
    "        probs = F.softmax(next_token_logits, dim=-1)\n",
    "        (batch, vocab_size) = probs.shape\n",
    "        \n",
    "        if top_k is not None:\n",
    "            (values, indices) = torch.topk(probs, k=top_k)\n",
    "            probs[probs < values[:, -1, None]] = 0\n",
    "            probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "        \n",
    "        if sample:\n",
    "            next_indices = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            next_indices = torch.argmax(probs, dim=-1)[:, None]\n",
    "        \n",
    "        input_ids = torch.cat([input_ids, next_indices], dim=1)\n",
    "\n",
    "    output_completions = [tokenizer.decode(output.tolist()) for output in input_ids][0]\n",
    "    \n",
    "    return output_completions\n",
    "\n",
    "print(generate(model_torch, tokenizer, 'John: Hi!\\nSally:', sample=False, n_tokens_to_gen=40, top_k=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(10, dtype=int32), Array([ 1,  3,  6, 10], dtype=int32))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def step(x1, x2):\n",
    "    return x1 + x2, x1 + x2\n",
    "\n",
    "carry, ys = jax.lax.scan(step, init=0, xs=jnp.array([1, 2, 3, 4]))\n",
    "# carry: 6\n",
    "# ys: [2, 6, 12]\n",
    "\n",
    "carry, ys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 1,  3,  6, 10], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine(x1, x2):\n",
    "    return x1 + x2\n",
    "\n",
    "result = jax.lax.associative_scan(combine, jnp.array([1, 2, 3, 4]))\n",
    "# result: [1, 3, 6, 10]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [1 2 3 4 5]\n",
      "Cumulative sum with scan: [ 1  3  6 10 15]\n",
      "Cumulative sum with associative scan: [ 1  3  6 10 15]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Sequential implementation with jax.lax.scan\n",
    "def cumulative_sum_scan(xs):\n",
    "    def step(carry, x):\n",
    "        carry = carry + x\n",
    "        return carry, carry  # Update carry and output it\n",
    "    _, ys = jax.lax.scan(step, 0, xs)  # Initial carry = 0\n",
    "    return ys\n",
    "\n",
    "# Parallel implementation with jax.lax.associative_scan\n",
    "def cumulative_sum_associative_scan(xs):\n",
    "    def combine(x1, x2):\n",
    "        return x1 + x2\n",
    "    return jax.lax.associative_scan(combine, xs)\n",
    "\n",
    "# Example input\n",
    "xs = jnp.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Compute with both methods\n",
    "result_scan = cumulative_sum_scan(xs)\n",
    "result_associative_scan = cumulative_sum_associative_scan(xs)\n",
    "\n",
    "# Print results\n",
    "print(\"Input:\", xs)\n",
    "print(\"Cumulative sum with scan:\", result_scan)\n",
    "print(\"Cumulative sum with associative scan:\", result_associative_scan)\n",
    "\n",
    "# Verify equality\n",
    "assert jnp.allclose(result_scan, result_associative_scan), \"Results do not match!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs are close: True\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from einops import einsum\n",
    "\n",
    "# Standard scan implementation\n",
    "\n",
    "\n",
    "def run_standard_scan(Ab, Bb_u, Cb):\n",
    "    def step(x_k_1, inputs):\n",
    "        Ab_k, Bb_u_k, Cb_k = inputs\n",
    "        x_k = Ab_k * x_k_1 + Bb_u_k\n",
    "        y_k = einsum(x_k, Cb_k, 'b d_in n, b n -> b d_in')\n",
    "        return x_k, y_k\n",
    "\n",
    "    x0 = jnp.zeros((B, D_in, n))\n",
    "    _, ys = jax.lax.scan(step, x0, (Ab, Bb_u, Cb))\n",
    "    return ys\n",
    "\n",
    "\n",
    "def run_parallel_scan(Ab, Bb_u, Cb):\n",
    "    # Associative operation\n",
    "    def combine_parallel(state1, state2):\n",
    "        # (a_1​,b_1​)⊕(a_2​,b_2​)=(a_1 * ​a_2​,a_2 *​ b_1​ + b_2​)\n",
    "        fl, xl = state1\n",
    "        fr, xr = state2\n",
    "        f = fr * fl\n",
    "        x = fr * xl + xr\n",
    "        return f, x\n",
    "\n",
    "    # Perform associative scan\n",
    "    results = jax.lax.associative_scan(combine_parallel, (Ab, Bb_u))\n",
    "\n",
    "    return einsum(results[1], Cb, 'l b d_in n, l b n -> l b d_in')\n",
    "\n",
    "# Example inputs\n",
    "B, L, D_in, n = 2, 5, 4, 3  # Batch, sequence length, input dim, model dim\n",
    "Ab = jnp.arange(0, L* B* D_in* n).reshape((L, B, D_in, n)) / 100\n",
    "Bb_u = jnp.arange(0, L* B* D_in* n).reshape((L, B, D_in, n))/ 100\n",
    "Cb = jnp.arange(0, L* B* n).reshape((L, B, n)) / 100\n",
    "\n",
    "# Compare outputs\n",
    "standard_output = run_standard_scan(Ab, Bb_u, Cb)\n",
    "parallel_output = run_parallel_scan(Ab, Bb_u, Cb)\n",
    "\n",
    "# Verify if the outputs are close\n",
    "is_close = jnp.allclose(standard_output, parallel_output, atol=1e-6)\n",
    "print(f\"Outputs are close: {is_close}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example inputs\n",
    "B, L, D_in, n = 2, 1000000, 4, 3  # Batch, sequence length, input dim, model dim\n",
    "Ab = jnp.arange(0, L* B* D_in* n).reshape((L, B, D_in, n)) / 100\n",
    "Bb_u = jnp.arange(0, L* B* D_in* n).reshape((L, B, D_in, n))/ 100\n",
    "Cb = jnp.arange(0, L* B* n).reshape((L, B, n)) / 100\n",
    "\n",
    "# Compare outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6 s ± 61.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "standard_output = run_standard_scan(Ab, Bb_u, Cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.6 ms ± 7.23 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "parallel_output = run_parallel_scan(Ab, Bb_u, Cb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba_fast_simple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
